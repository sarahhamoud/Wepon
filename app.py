import streamlit as st
from ultralytics import YOLO
from pathlib import Path
import tempfile
from PIL import Image
import cv2
import numpy as np

# =========================
# Ø¥Ø¹Ø¯Ø§Ø¯ Ø§Ù„ØµÙØ­Ø©
# =========================
st.set_page_config(
    page_title="ÙƒØ´Ù Ø§Ù„Ø£Ø³Ù„Ø­Ø© Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… YOLO",
    layout="wide",
    initial_sidebar_state="expanded"
)

# =========================
# CSS: RTL + Ø£Ù„ÙˆØ§Ù† ÙØ§ØªØ­Ø© + Ø®Ø· Ø£ÙˆØ¶Ø­ + ÙˆØ§Ø¬Ù‡Ø© Ù‡Ù†Ø¯Ø³ÙŠØ©
# =========================
st.markdown(
    """
    <style>
    :root{
      --bg:#f7f9fc;
      --card:#ffffff;
      --text:#0f172a;
      --muted:#475569;
      --primary:#2563eb;
      --primary2:#06b6d4;
      --border:#e2e8f0;
      --shadow: 0 10px 30px rgba(2, 6, 23, .08);
    }

    html, body, [data-testid="stApp"]{
        background: var(--bg);
        direction: RTL;
        text-align: right;
        font-family: "Segoe UI", Tahoma, Arial, sans-serif;
        color: var(--text);
    }

    /* Ø¥Ø²Ø§Ù„Ø© Ø§Ù„Ù‡ÙŠØ¯Ø± Ø§Ù„Ø¹Ù„ÙˆÙŠ Ø§Ù„Ø§ÙØªØ±Ø§Ø¶ÙŠ (Ø¥Ø°Ø§ ÙŠØ¸Ù‡Ø±) */
    header {visibility: hidden;}
    #MainMenu {visibility: hidden;}
    footer {visibility: hidden;}

    h1,h2,h3,h4,h5,h6,p,label,span,div{
        text-align: right !important;
        color: var(--text);
    }

    /* ØªÙƒØ¨ÙŠØ± Ø§Ù„Ø®Ø· Ø§Ù„Ø¹Ø§Ù… */
    .stMarkdown, .stTextInput, .stSelectbox, .stRadio, .stButton button{
        font-size: 16px !important;
    }

    /* Ø¨Ø·Ø§Ù‚Ø§Øª */
    .card{
        background: var(--card);
        border: 1px solid var(--border);
        border-radius: 18px;
        box-shadow: var(--shadow);
        padding: 16px 18px;
        margin-bottom: 16px;
    }

    /* Ø¹Ù†ÙˆØ§Ù† Ø¹Ù„ÙˆÙŠ */
    .topbar{
        display:flex;
        justify-content: space-between;
        align-items:center;
        gap: 12px;
        padding: 14px 16px;
        border-radius: 18px;
        background: linear-gradient(135deg, rgba(37,99,235,.08), rgba(6,182,212,.10));
        border: 1px solid rgba(37,99,235,.18);
        box-shadow: var(--shadow);
        margin-bottom: 16px;
    }
    .brand{
        font-weight: 700;
        font-size: 22px;
        color: var(--text);
        margin:0;
    }
    .owner{
        font-weight: 600;
        font-size: 14px;
        color: var(--muted);
        margin:0;
        direction:ltr;
        text-align:left !important;
    }

    /* Ø§Ù„Ø£Ø²Ø±Ø§Ø± */
    .stButton button{
        border-radius: 14px !important;
        border: 1px solid rgba(37,99,235,.25) !important;
        padding: 12px 14px !important;
        font-weight: 700 !important;
        background: #ffffff !important;
        color: var(--text) !important;
        box-shadow: 0 8px 22px rgba(2, 6, 23, .06) !important;
        transition: all .2s ease;
    }
    .stButton button:hover{
        transform: translateY(-1px);
        border-color: rgba(37,99,235,.45) !important;
        box-shadow: 0 14px 30px rgba(2, 6, 23, .10) !important;
    }

    /* Ø§Ù„Ø±Ø§Ø¯ÙŠÙˆ/Ø§Ù„Ø§Ø®ØªÙŠØ§Ø±Ø§Øª */
    [data-testid="stRadio"]{
        background: #fff;
        border: 1px solid var(--border);
        border-radius: 16px;
        padding: 12px 14px;
        box-shadow: 0 10px 25px rgba(2, 6, 23, .06);
    }

    /* Ù…Ø¯Ø®Ù„Ø§Øª */
    .stTextInput input, .stSelectbox div[data-baseweb="select"]{
        border-radius: 14px !important;
    }

    /* ØªÙ†Ø³ÙŠÙ‚ Ø±Ø³Ø§Ø¦Ù„ Ø§Ù„Ø­Ø§Ù„Ø© */
    .stAlert{
        border-radius: 14px !important;
    }
    </style>
    """,
    unsafe_allow_html=True
)

# =========================
# Ø´Ø±ÙŠØ· Ø¹Ù„ÙˆÙŠ (Ø¨Ø¯ÙˆÙ† â€œØ¨ÙŠØ¦Ø© Ø¹Ø±Ø¨ÙŠØ©â€)
# =========================
st.markdown(
    """
    <div class="topbar">
      <p class="brand">ØªØ·Ø¨ÙŠÙ‚ ÙƒØ´Ù Ø§Ù„Ø£Ø³Ù„Ø­Ø© Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… YOLO</p>
      <p class="owner">sarah hamoud hussien</p>
    </div>
    """,
    unsafe_allow_html=True
)

st.markdown(
    """
    <div class="card">
      <p style="margin:0;color:#334155;font-weight:600;">
      Ø§Ø®ØªØ§Ø±ÙŠ ÙˆØ¶Ø¹ Ø§Ù„Ø¹Ù…Ù„: <b>ØµÙˆØ±Ø©</b> Ø£Ùˆ <b>ÙÙŠØ¯ÙŠÙˆ</b> Ø£Ùˆ <b>ÙƒØ§Ù…ÙŠØ±Ø§ Ø§Ù„Ù‡Ø§ØªÙ/Ø§Ù„Ø­Ø§Ø³ÙˆØ¨</b>.
      </p>
    </div>
    """,
    unsafe_allow_html=True
)

# =========================
# Ù…Ø³Ø§Ø±Ø§Øª Ø§Ù„Ù…Ø´Ø±ÙˆØ¹ (Ù…Ù†Ø§Ø³Ø¨Ø© Ù„Ù„Ù…ÙˆØ¨Ø§ÙŠÙ„/Ø§Ù„Ø³ÙŠØ±ÙØ±)
# =========================
BASE_DIR = Path(__file__).resolve().parent
MODEL_PATH = BASE_DIR / "models" / "best.pt"
OUTPUT_DIR = BASE_DIR / "outputs" / "video_inference"
OUTPUT_DIR.mkdir(parents=True, exist_ok=True)

# =========================
# ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ù…ÙˆØ¯ÙŠÙ„ Ù…Ø±Ø© ÙˆØ§Ø­Ø¯Ø©
# =========================
@st.cache_resource
def load_model(path: Path):
    return YOLO(str(path))

if not MODEL_PATH.exists():
    st.error("Ù…Ù„Ù Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ ØºÙŠØ± Ù…ÙˆØ¬ÙˆØ¯! Ø¶Ø¹ÙŠ best.pt Ø¯Ø§Ø®Ù„ Ù…Ø¬Ù„Ø¯: models/")
    st.stop()

model = load_model(MODEL_PATH)

# =========================
# Ø±Ø³Ù… Ø¬Ù…ÙŠØ¹ Ø§Ù„Ù…Ø±Ø¨Ø¹Ø§Øª
# =========================
def draw_boxes(frame_bgr, results):
    for r in results:
        boxes = r.boxes
        if boxes is None or len(boxes) == 0:
            continue

        for box in boxes:
            x1, y1, x2, y2 = box.xyxy[0].cpu().numpy().astype(int)
            conf = float(box.conf[0].cpu().numpy())
            cls = int(box.cls[0].cpu().numpy())
            label = f"{model.names.get(cls, 'obj')} {conf:.2f}"

            cv2.rectangle(frame_bgr, (x1, y1), (x2, y2), (0, 180, 0), 2)
            cv2.putText(frame_bgr, label, (x1, max(y1 - 10, 10)),
                        cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 180, 0), 2)

    return frame_bgr

# =========================
# Ù…Ø¹Ø§Ù„Ø¬Ø© ÙÙŠØ¯ÙŠÙˆ ÙƒØ§Ù…Ù„ Ù…Ø¹ ØªÙ‚Ø¯Ù…
# =========================
def process_video(input_path: str, output_path: Path, conf=0.20, iou=0.40, imgsz=640):
    cap = cv2.VideoCapture(input_path)
    if not cap.isOpened():
        raise RuntimeError("âŒ Ù„Ø§ ÙŠÙ…ÙƒÙ† ÙØªØ­ Ù…Ù„Ù Ø§Ù„ÙÙŠØ¯ÙŠÙˆ")

    total = int(cap.get(cv2.CAP_PROP_FRAME_COUNT)) or 0
    prog = st.progress(0)
    txt = st.empty()

    fps = cap.get(cv2.CAP_PROP_FPS) or 25
    width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))
    height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))

    fourcc = cv2.VideoWriter_fourcc(*"mp4v")
    out = cv2.VideoWriter(str(output_path), fourcc, fps, (width, height))

    frame_count = 0
    while True:
        ret, frame = cap.read()
        if not ret:
            break

        frame_count += 1

        results = model(frame, imgsz=imgsz, conf=conf, iou=iou)
        annotated = draw_boxes(frame, results)
        out.write(annotated)

        if total > 0:
            prog.progress(min(frame_count / total, 1.0))
            txt.write(f"Ø¬Ø§Ø±ÙŠ Ø§Ù„Ù…Ø¹Ø§Ù„Ø¬Ø©: {frame_count} / {total} Ø¥Ø·Ø§Ø±")

    cap.release()
    out.release()
    prog.progress(1.0)
    txt.write("âœ… Ø§ÙƒØªÙ…Ù„Øª Ø§Ù„Ù…Ø¹Ø§Ù„Ø¬Ø©")

# =========================
# Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª Ø§Ù„ÙƒØ´Ù
# =========================
with st.sidebar:
    st.markdown("### Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª Ø§Ù„ÙƒØ´Ù")
    conf_th = st.slider("Ø¹ØªØ¨Ø© Ø§Ù„Ø«Ù‚Ø© (Confidence)", 0.05, 0.90, 0.20, 0.05)
    iou_th = st.slider("Ø¹ØªØ¨Ø© Ø§Ù„ØªØ¯Ø§Ø®Ù„ (IoU)", 0.05, 0.90, 0.40, 0.05)
    img_size = st.select_slider("Ø­Ø¬Ù… Ø§Ù„Ø¥Ø¯Ø®Ø§Ù„ (imgsz)", options=[320, 416, 512, 640, 768], value=640)
    st.markdown("---")
    st.markdown("### Ù…Ù„Ø§Ø­Ø¸Ø© Ù„Ù„Ù…ÙˆØ¨Ø§ÙŠÙ„")
    st.caption("ÙˆØ¶Ø¹ Ø§Ù„ÙƒØ§Ù…ÙŠØ±Ø§ ÙŠØ¹Ù…Ù„ Ø¹Ù„Ù‰ Ø§Ù„Ù‡Ø§ØªÙ Ø¹Ø¨Ø± Ø§Ù„ØªÙ‚Ø§Ø· ØµÙˆØ±Ø© ÙˆØ§Ø­Ø¯Ø©. Ø¨Ø« Ù…Ø¨Ø§Ø´Ø± ØºÙŠØ± Ù…Ø¯Ø¹ÙˆÙ… ÙÙŠ Streamlit.")

# =========================
# ÙˆØ¶Ø¹ Ø§Ù„ØµÙˆØ±Ø©
# =========================
def run_image_mode():
    st.markdown('<div class="card">', unsafe_allow_html=True)
    st.subheader("ğŸ–¼ï¸ ÙˆØ¶Ø¹ Ø§Ù„ØµÙˆØ±Ø©")
    uploaded_file = st.file_uploader("Ø§Ø±ÙØ¹/Ø§Ø±ÙØ¹ÙŠ ØµÙˆØ±Ø©", type=["jpg", "jpeg", "png"])
    st.markdown("</div>", unsafe_allow_html=True)

    if uploaded_file is not None:
        image = Image.open(uploaded_file).convert("RGB")
        st.image(image, caption="Ø§Ù„ØµÙˆØ±Ø© Ø§Ù„Ø£ØµÙ„ÙŠØ©", use_container_width=True)

        with st.spinner("Ø¬Ø§Ø±ÙŠ Ø§Ù„ÙƒØ´Ù..."):
            img_np = np.array(image)
            img_bgr = cv2.cvtColor(img_np, cv2.COLOR_RGB2BGR)

            results = model(img_bgr, imgsz=img_size, conf=conf_th, iou=iou_th)

            annotated_bgr = draw_boxes(img_bgr.copy(), results)
            annotated_rgb = cv2.cvtColor(annotated_bgr, cv2.COLOR_BGR2RGB)

        st.success("ØªÙ… Ø§Ù„ÙƒØ´Ù âœ…")
        st.image(annotated_rgb, caption="Ø§Ù„Ù†ØªÙŠØ¬Ø©", use_container_width=True)

# =========================
# ÙˆØ¶Ø¹ Ø§Ù„ÙÙŠØ¯ÙŠÙˆ
# =========================
def run_video_mode():
    st.markdown('<div class="card">', unsafe_allow_html=True)
    st.subheader("ğŸ¬ ÙˆØ¶Ø¹ Ø§Ù„ÙÙŠØ¯ÙŠÙˆ")
    video_file = st.file_uploader("Ø§Ø±ÙØ¹/Ø§Ø±ÙØ¹ÙŠ ÙÙŠØ¯ÙŠÙˆ", type=["mp4", "avi", "mov", "mkv"])
    st.markdown("</div>", unsafe_allow_html=True)

    if video_file is not None:
        tfile = tempfile.NamedTemporaryFile(delete=False, suffix=".mp4")
        tfile.write(video_file.read())
        tfile.flush()

        st.video(tfile.name)

        colA, colB = st.columns([1, 1])
        with colA:
            start = st.button("ğŸš€ Ø¨Ø¯Ø¡ Ø§Ù„Ù…Ø¹Ø§Ù„Ø¬Ø©", use_container_width=True)
        with colB:
            st.caption("Ù†ØµÙŠØ­Ø©: ÙÙŠØ¯ÙŠÙˆÙ‡Ø§Øª Ù‚ØµÙŠØ±Ø© Ø£ÙØ¶Ù„ Ù„Ù„Ù…ÙˆØ¨Ø§ÙŠÙ„.")

        if start:
            st.info("Ø¬Ø§Ø±ÙŠ Ø§Ù„Ù…Ø¹Ø§Ù„Ø¬Ø©... Ù‚Ø¯ ÙŠØ³ØªØºØ±Ù‚ Ø°Ù„Ùƒ Ø­Ø³Ø¨ Ø·ÙˆÙ„ Ø§Ù„ÙÙŠØ¯ÙŠÙˆ.")
            output_path = OUTPUT_DIR / (Path(video_file.name).stem + "_processed.mp4")

            process_video(tfile.name, output_path, conf=conf_th, iou=iou_th, imgsz=img_size)

            st.success("ØªÙ…Øª Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„ÙÙŠØ¯ÙŠÙˆ Ø¨Ù†Ø¬Ø§Ø­ âœ…")

            st.markdown("#### ØªØ­Ù…ÙŠÙ„ Ø§Ù„ÙÙŠØ¯ÙŠÙˆ Ø§Ù„Ù…Ø¹Ø§Ù„Ø¬")
            with open(output_path, "rb") as f:
                st.download_button(
                    label="â¬‡ï¸ ØªÙ†Ø²ÙŠÙ„ Ø§Ù„ÙÙŠØ¯ÙŠÙˆ Ø¨Ø¹Ø¯ Ø§Ù„Ù…Ø¹Ø§Ù„Ø¬Ø©",
                    data=f.read(),
                    file_name=output_path.name,
                    mime="video/mp4",
                    use_container_width=True
                )

# =========================
# ÙˆØ¶Ø¹ Ø§Ù„ÙƒØ§Ù…ÙŠØ±Ø§ (Ù…ÙˆØ¨Ø§ÙŠÙ„/Ø­Ø§Ø³ÙˆØ¨)
# =========================
def run_camera_mode():
    st.markdown('<div class="card">', unsafe_allow_html=True)
    st.subheader("ğŸ“¸ ÙˆØ¶Ø¹ Ø§Ù„ÙƒØ§Ù…ÙŠØ±Ø§ (Ø§Ù„ØªÙ‚Ø§Ø· ØµÙˆØ±Ø©)")
    st.write("Ø¹Ù„Ù‰ Ø§Ù„Ù‡Ø§ØªÙ: Ø³ÙŠÙØªØ­ Ø§Ù„ÙƒØ§Ù…ÙŠØ±Ø§ Ù…Ø¨Ø§Ø´Ø±Ø©. Ø¹Ù„Ù‰ Ø§Ù„Ø­Ø§Ø³ÙˆØ¨: ÙŠØ³ØªØ®Ø¯Ù… ÙƒØ§Ù…ÙŠØ±Ø§ Ø§Ù„Ù„Ø§Ø¨ØªÙˆØ¨ Ø¥Ù† ÙˆÙØ¬Ø¯Øª.")
    st.markdown("</div>", unsafe_allow_html=True)

    img_data = st.camera_input("Ø§Ù„ØªÙ‚Ø·/Ø§Ù„ØªÙ‚Ø·ÙŠ ØµÙˆØ±Ø©")

    if img_data is not None:
        image = Image.open(img_data).convert("RGB")
        st.image(image, caption="Ø§Ù„ØµÙˆØ±Ø© Ø§Ù„Ù…Ù„ØªÙ‚Ø·Ø©", use_container_width=True)

        with st.spinner("Ø¬Ø§Ø±ÙŠ Ø§Ù„ÙƒØ´Ù..."):
            img_np = np.array(image)
            img_bgr = cv2.cvtColor(img_np, cv2.COLOR_RGB2BGR)

            results = model(img_bgr, imgsz=img_size, conf=conf_th, iou=iou_th)

            annotated_bgr = draw_boxes(img_bgr.copy(), results)
            annotated_rgb = cv2.cvtColor(annotated_bgr, cv2.COLOR_BGR2RGB)

        st.success("ØªÙ… Ø§Ù„ÙƒØ´Ù âœ…")
        st.image(annotated_rgb, caption="Ø§Ù„Ù†ØªÙŠØ¬Ø©", use_container_width=True)

# =========================
# ÙˆØ§Ø¬Ù‡Ø© Ø§Ù„Ø£ÙˆØ¶Ø§Ø¹ (Ø£Ø²Ø±Ø§Ø± ÙƒØ¨ÙŠØ±Ø©)
# =========================
if "mode" not in st.session_state:
    st.session_state["mode"] = "image"

cols = st.columns(3)
with cols[0]:
    if st.button("ğŸ–¼ï¸ ØµÙˆØ±Ø©", use_container_width=True):
        st.session_state["mode"] = "image"
with cols[1]:
    if st.button("ğŸ¬ ÙÙŠØ¯ÙŠÙˆ", use_container_width=True):
        st.session_state["mode"] = "video"
with cols[2]:
    if st.button("ğŸ“¸ ÙƒØ§Ù…ÙŠØ±Ø§", use_container_width=True):
        st.session_state["mode"] = "camera"

st.markdown("---")

mode = st.session_state["mode"]
if mode == "image":
    run_image_mode()
elif mode == "video":
    run_video_mode()
elif mode == "camera":
    run_camera_mode()
